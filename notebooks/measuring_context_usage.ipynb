{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitdialogmtcondaaf9d4fe34c0b48b29c1c56956f51d584",
   "display_name": "Python 3.7.9 64-bit ('dialog_mt': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Measuring Context Usage with CXMI\n",
    "\n",
    "This notebook contains the code to measure CXMI for contextual models trained in this libray\n",
    "\n",
    "Start by setting the path for your checkpoint of interest. This should ideally be a model trained with *dynamic* context size. \n",
    "We also need set context size for which we are measuring CXMI. We also need to set the languages in order to load the sentencepiece models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt=\"/projects/tir5/users/patrick/checkpoints/iwslt2017/en-fr/one_to_five_sampled_1/\"\n",
    "source_context_size=0\n",
    "target_context_size=1\n",
    "source_lang=\"en\"\n",
    "target_lang=\"fr\""
   ]
  },
  {
   "source": [
    "And then load the models and associated files such as the vocabularies into memory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data import data_utils\n",
    "from fairseq.sequence_scorer import SequenceScorer\n",
    "\n",
    "from fairseq.data import data_utils\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import sentencepiece as sp\n",
    "\n",
    "import contextual_mt\n",
    "from contextual_mt.contextual_dataset import collate as contextual_collate\n",
    "from contextual_mt.utils import encode, decode, create_context\n",
    "\n",
    "from contextual_mt.contextual_dataset import collate\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "#baseline_ckpt=\"/projects/tir5/users/patrick/checkpoints/iwslt2017/en-de/baseline_pretrained_3/\"\n",
    "contextual_ckpt=\"/projects/tir5/users/patrick/checkpoints/iwslt2017/en-fr/one_to_five_sampled_1/\"\n",
    "use_contrastive=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'contextual_ckpt' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-caabdc42e336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m package = hub_utils.from_pretrained(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcontextual_ckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"checkpoint_best.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'contextual_ckpt' is not defined"
     ]
    }
   ],
   "source": [
    "from fairseq import utils, hub_utils\n",
    "\n",
    "package = hub_utils.from_pretrained(\n",
    "    model_ckpt, checkpoint_file=\"checkpoint_best.pt\"\n",
    ")\n",
    "models = package[\"models\"]\n",
    "for model in models:\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "# load dict, params and generator from task\n",
    "src_dict = package[\"task\"].src_dict\n",
    "tgt_dict = package[\"task\"].tgt_dict\n",
    "\n",
    "scorer = SequenceScorer(tgt_dict)\n",
    "\n",
    "# load sentencepiece models (assumes they are in the checkpoint dirs)\n",
    "# FIXME: is there someway to have it in `package`\n",
    "if os.path.exists(os.path.join(model_ckpt, \"spm.model\")):\n",
    "    spm = sp.SentencePieceProcessor()\n",
    "    spm.Load(os.path.join(model_ckpt, \"spm.model\"))\n",
    "    src_spm = spm\n",
    "    tgt_spm = spm\n",
    "else:\n",
    "    src_spm = sp.SentencePieceProcessor()\n",
    "    src_spm.Load(os.path.join(model_ckpt, f\"spm.{source_lang}.model\"))\n",
    "    tgt_spm = sp.SentencePieceProcessor()\n",
    "    tgt_spm.Load(os.path.join(model_ckpt, f\"spm.{target_lang}.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_file=\"/projects/tir1/corpora/dialogue_mt/iwslt2017/en-de/test.en-de.en\"\n",
    "target_file=\"/projects/tir1/corpora/dialogue_mt/iwslt2017/en-de/test.en-de.de\"\n",
    "docids_file=\"/projects/tir1/corpora/dialogue_mt/iwslt2017/en-de/test.en-de.docids\"\n",
    "batch_size=4\n",
    "\n",
    "if not use_contrastive:\n",
    "    # load files needed\n",
    "    with open(source_file, \"r\") as src_f:\n",
    "        srcs = [line.strip() for line in src_f]\n",
    "    with open(docids_file, \"r\") as docids_f:\n",
    "        docids = [int(idx) for idx in docids_f]\n",
    "    with open(target_file, \"r\") as tgt_f:\n",
    "        refs = [line.strip() for line in tgt_f]\n",
    "\n",
    "    srcs_encoded = [encode(src_l, src_spm, src_dict) for src_l in srcs]\n",
    "    refs_encoded = [encode(tgt_l, tgt_spm, tgt_dict) for tgt_l in refs]\n",
    "    # parse lines into list of documents\n",
    "    documents = []\n",
    "    prev_docid = None\n",
    "    for src_l, tgt_l, idx in zip(srcs, refs, docids):\n",
    "        if prev_docid != idx:\n",
    "            documents.append([])\n",
    "        prev_docid = idx\n",
    "        documents[-1].append((src_l, tgt_l))\n",
    "\n",
    "    preds = []\n",
    "    ids = []\n",
    "    scores = []\n",
    "    src_context_lines = [[] for _ in range(batch_size)]\n",
    "    tgt_context_lines = [[] for _ in range(batch_size)]\n",
    "\n",
    "    # info necessary to create batches and recreate docs\n",
    "    doc_idx = 0\n",
    "    current_docs = [None for _ in range(batch_size)]\n",
    "    current_docs_ids = [-1 for _ in range(batch_size)]\n",
    "    current_docs_pos = [0 for _ in range(batch_size)]\n",
    "    baseline_xes = []\n",
    "    contextual_xes = []\n",
    "    total_xmi = 0 \n",
    "    num_samples = 0\n",
    "    while True:\n",
    "        batch_map = []\n",
    "        batch_targets = []\n",
    "        baseline_samples = []\n",
    "        contextual_samples = []\n",
    "        random_samples = []\n",
    "        for idx in range(batch_size):\n",
    "            # if any of the docs in the batch has finished replace by a new one\n",
    "            if current_docs[idx] is None or current_docs_pos[idx] >= len(\n",
    "                current_docs[idx]\n",
    "            ):\n",
    "                if doc_idx < len(documents):\n",
    "                    current_docs[idx] = documents[doc_idx]\n",
    "                    current_docs_ids[idx] = doc_idx\n",
    "                    current_docs_pos[idx] = 0\n",
    "                    src_context_lines[idx] = []\n",
    "                    tgt_context_lines[idx] = []\n",
    "                    doc_idx += 1\n",
    "                else:\n",
    "                    current_docs[idx] = None\n",
    "                    continue\n",
    "\n",
    "            src_l, tgt_l = current_docs[idx][current_docs_pos[idx]]\n",
    "\n",
    "            ids.append((current_docs_ids[idx], current_docs_pos[idx]))\n",
    "\n",
    "            # binarize source and create input with context and target\n",
    "            source_noeos = encode(src_l, src_spm, src_dict)\n",
    "            source = torch.stack([*source_noeos, torch.tensor(src_dict.eos())])\n",
    "            target_noeos = encode(tgt_l, tgt_spm, tgt_dict)\n",
    "            target = torch.stack([*target_noeos, torch.tensor(tgt_dict.eos())])\n",
    "\n",
    "            random_src_pool = [srcs_encoded[idx] for idx in np.random.randint(0, len(srcs), size=source_context_size)]\n",
    "            random_tgt_pool = [refs_encoded[idx] for idx in np.random.randint(0, len(refs), size=target_context_size)]\n",
    "\n",
    "            baseline_src_context = create_context(\n",
    "                src_context_lines[idx],\n",
    "                0,\n",
    "                break_id=src_dict.index(\"<brk>\"),\n",
    "                eos_id=src_dict.eos(),\n",
    "            )\n",
    "            baseline_tgt_context = create_context(\n",
    "                tgt_context_lines[idx],\n",
    "                0,\n",
    "                break_id=tgt_dict.index(\"<brk>\"),\n",
    "                eos_id=tgt_dict.eos(),\n",
    "            )\n",
    "            random_src_context = create_context(\n",
    "                random_src_pool,\n",
    "                source_context_size,\n",
    "                break_id=src_dict.index(\"<brk>\"),\n",
    "                eos_id=src_dict.eos()\n",
    "            )\n",
    "            random_tgt_context = create_context(\n",
    "                random_tgt_pool,\n",
    "                target_context_size,\n",
    "                break_id=tgt_dict.index(\"<brk>\"),\n",
    "                eos_id=tgt_dict.eos()\n",
    "            )\n",
    "\n",
    "            random_samples.append(\n",
    "                {\n",
    "                    \"id\": 0,\n",
    "                    \"src_context\": random_src_context,\n",
    "                    \"source\": source,\n",
    "                    \"tgt_context\": random_tgt_context,\n",
    "                    \"target\": target\n",
    "                }\n",
    "            )\n",
    "            baseline_samples.append(\n",
    "                {\n",
    "                    \"id\": 0,\n",
    "                    \"src_context\": baseline_src_context,\n",
    "                    \"source\": source,\n",
    "                    \"tgt_context\": baseline_tgt_context,\n",
    "                    \"target\": target\n",
    "                }\n",
    "            )\n",
    "\n",
    "            contextual_src_context = create_context(\n",
    "                src_context_lines[idx],\n",
    "                source_context_size,\n",
    "                break_id=src_dict.index(\"<brk>\"),\n",
    "                eos_id=src_dict.eos(),\n",
    "            )\n",
    "            contextual_tgt_context = create_context(\n",
    "                tgt_context_lines[idx],\n",
    "                target_context_size,\n",
    "                break_id=tgt_dict.index(\"<brk>\"),\n",
    "                eos_id=tgt_dict.eos(),\n",
    "            )\n",
    "            contextual_samples.append(\n",
    "                {\n",
    "                    \"id\": 0,\n",
    "                    \"src_context\": contextual_src_context,\n",
    "                    \"source\": source,\n",
    "                    \"tgt_context\": contextual_tgt_context,\n",
    "                    \"target\": target\n",
    "                }\n",
    "            )\n",
    "\n",
    "            src_context_lines[idx].append(source_noeos)\n",
    "            tgt_context_lines[idx].append(target_noeos)\n",
    "\n",
    "            current_docs_pos[idx] += 1\n",
    "\n",
    "        # while exit condition\n",
    "        if all(chat is None for chat in current_docs):\n",
    "            break\n",
    "\n",
    "        # create batch\n",
    "        baseline_sample = collate(\n",
    "            baseline_samples, src_dict.pad(), src_dict.eos()\n",
    "        )\n",
    "        baseline_sample = utils.move_to_cuda(baseline_sample)\n",
    "        contextual_sample = collate(\n",
    "            contextual_samples, src_dict.pad(), src_dict.eos()\n",
    "        )\n",
    "        contextual_sample = utils.move_to_cuda(contextual_sample)\n",
    "\n",
    "        baseline_output = scorer.generate(contextual_models, baseline_sample)\n",
    "        contextual_output = scorer.generate(contextual_models, contextual_sample)\n",
    "        for batch_idx in range(len(baseline_samples)):\n",
    "            # decode hypothesis\n",
    "            baseline_xes.append(baseline_output[batch_idx][0][\"score\"].cpu())\n",
    "            contextual_xes.append(contextual_output[batch_idx][0][\"score\"].cpu())\n",
    "            total_xmi+=baseline_xes[-1] - contextual_xes[-1]\n",
    "            num_samples+=1\n",
    "            \n",
    "    all_baseline_xes.append(baseline_xes)\n",
    "    all_contextual_xes.append(contextual_xes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextual_mt.docmt_contrastive_eval import load_contrastive\n",
    "\n",
    "bawden=True\n",
    "if bawden:\n",
    "    source_file=\"/home/pfernand/repos/discourse-mt-test-sets/test-sets/lexical_choice.current.en\"\n",
    "    target_file=\"/home/pfernand/repos/discourse-mt-test-sets/test-sets/lexical_choice.current.fr\"\n",
    "    src_context_file=\"/home/pfernand/repos/discourse-mt-test-sets/test-sets/lexical_choice.prev.en\"\n",
    "    tgt_context_file=\"/home/pfernand/repos/discourse-mt-test-sets/test-sets/lexical_choice.prev.fr\"\n",
    "else:\n",
    "    source_file=\"/home/pfernand/repos/ContraPro/contrapro.text.en\"\n",
    "    target_file=\"/home/pfernand/repos/ContraPro/contrapro.text.de\"\n",
    "    src_context_file=\"/home/pfernand/repos/ContraPro/contrapro.context.en\"\n",
    "    tgt_context_file=\"/home/pfernand/repos/ContraPro/contrapro.context.de\"\n",
    "\n",
    "\n",
    "if use_contrastive:\n",
    "    # load files\n",
    "    srcs, all_tgts, tgt_labels, srcs_contexts, tgts_contexts = load_contrastive(\n",
    "        source_file, target_file, src_context_file, tgt_context_file, dataset=\"bawden\" if bawden else \"contrapro\"\n",
    "    )\n",
    "    baseline_xes = []\n",
    "    contextual_xes = []\n",
    "    corrects = []\n",
    "    b_corrects = []\n",
    "    for src, src_ctx, contr_tgts, tgt_ctx in zip(srcs, srcs_contexts, all_tgts, tgts_contexts):\n",
    "        src = encode(src, src_spm, src_dict)\n",
    "        src_ctx = [encode(ctx, src_spm, src_dict) for ctx in src_ctx]\n",
    "        contr_tgts = [encode(tgt, tgt_spm, tgt_dict) for tgt in contr_tgts]\n",
    "        tgt_ctx = [encode(ctx, tgt_spm, tgt_dict) for ctx in tgt_ctx]\n",
    "        baseline_samples = []\n",
    "        contextual_samples = []\n",
    "\n",
    "        for tgt in contr_tgts:\n",
    "            baseline_src_context = create_context(\n",
    "                src_ctx,\n",
    "                0,\n",
    "                break_id=src_dict.index(\"<brk>\"),\n",
    "                eos_id=src_dict.eos(),\n",
    "            )\n",
    "            baseline_tgt_context = create_context(\n",
    "                tgt_ctx,\n",
    "                0,\n",
    "                break_id=tgt_dict.index(\"<brk>\"),\n",
    "                eos_id=tgt_dict.eos(),\n",
    "            )\n",
    "            contextual_src_context = create_context(\n",
    "                src_ctx,\n",
    "                source_context_size,\n",
    "                break_id=src_dict.index(\"<brk>\"),\n",
    "                eos_id=src_dict.eos(),\n",
    "            )\n",
    "            contextual_tgt_context = create_context(\n",
    "                tgt_ctx,\n",
    "                target_context_size,\n",
    "                break_id=tgt_dict.index(\"<brk>\"),\n",
    "                eos_id=tgt_dict.eos())\n",
    "\n",
    "            full_src = torch.cat([src, torch.tensor([src_dict.eos()])])\n",
    "            full_tgt = torch.cat([tgt, torch.tensor([tgt_dict.eos()])])\n",
    "            baseline_sample = {\n",
    "                \"id\": 0,\n",
    "                \"source\": full_src,\n",
    "                \"src_context\": baseline_src_context,\n",
    "                \"target\": full_tgt,\n",
    "                \"tgt_context\": baseline_tgt_context,\n",
    "            }\n",
    "            contextual_sample = {\n",
    "                \"id\": 0,\n",
    "                \"source\": full_src,\n",
    "                \"src_context\": contextual_src_context,\n",
    "                \"target\": full_tgt,\n",
    "                \"tgt_context\": contextual_tgt_context,\n",
    "            }\n",
    "            baseline_samples.append(baseline_sample)\n",
    "            contextual_samples.append(contextual_sample)\n",
    "\n",
    "        baseline_sample = contextual_collate(\n",
    "            baseline_samples,\n",
    "            pad_id=src_dict.pad(),\n",
    "            eos_id=src_dict.eos(),\n",
    "        )\n",
    "        contextual_sample = contextual_collate(\n",
    "            contextual_samples,\n",
    "            pad_id=src_dict.pad(),\n",
    "            eos_id=src_dict.eos()\n",
    "        )\n",
    "\n",
    "        baseline_sample = utils.move_to_cuda(baseline_sample)\n",
    "        contextual_sample = utils.move_to_cuda(contextual_sample)\n",
    "\n",
    "        baseline_out = scorer.generate(contextual_models, baseline_sample)\n",
    "        contextual_out = scorer.generate(contextual_models, contextual_sample)\n",
    "\n",
    "        scores = [h[0][\"score\"] for h in contextual_out]\n",
    "\n",
    "        most_likely = torch.argmax(torch.stack(scores))\n",
    "        correct = most_likely == 0\n",
    "        baseline_correct = torch.argmax(torch.stack([h[0][\"score\"] for h in baseline_out])) == 0\n",
    "\n",
    "        b_corrects.append(baseline_correct)\n",
    "        corrects.append(correct)\n",
    "        baseline_xes.append(baseline_out[0][0][\"score\"])\n",
    "        contextual_xes.append(contextual_out[0][0][\"score\"])\n",
    "\n",
    "    all_baseline_xes.append(baseline_xes)\n",
    "    all_contextual_xes.append(contextual_xes)\n",
    "    corrects = np.stack([correct.cpu().numpy() for correct in corrects])\n",
    "    b_corrects = np.stack([b_correct.cpu().numpy() for b_correct in b_corrects])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "-0.7144931929047442\n"
     ]
    }
   ],
   "source": [
    "print(len(all_baseline_xes))\n",
    "def ensemble_xes_average(all_xes):\n",
    "    all_xes = zip(*all_xes)\n",
    "    avg_xes = []\n",
    "    for samples in all_xes:\n",
    "        avg_xes.append(np.log(np.mean([np.exp(xe.cpu()) for xe in samples])))\n",
    "    return avg_xes\n",
    "\n",
    "def calculate_xmi(model1_xes, model2_xes):\n",
    "    total_xmi = 0\n",
    "    num_samples = 0\n",
    "    for m1_xe, m2_xe in zip(model1_xes, model2_xes):\n",
    "        total_xmi += m1_xe - m2_xe\n",
    "        num_samples += 1\n",
    "    return -total_xmi/num_samples\n",
    "\n",
    "avg_baseline_xes = ensemble_xes_average(all_baseline_xes)\n",
    "avg_contextual_xes = ensemble_xes_average(all_contextual_xes)\n",
    "print(calculate_xmi(avg_baseline_xes, avg_contextual_xes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Acc: 0.57\nTotal Acc: 0.5\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "x and y must have the same length.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-3926b75038d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total Acc: {np.stack(corrects).mean().item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total Acc: {np.stack(b_corrects).mean().item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointbiserialr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcxe\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbxe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcxe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbxe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_contextual_xes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_baseline_xes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointbiserialr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mb_c\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_corrects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcxe\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbxe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcxe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbxe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_contextual_xes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_baseline_xes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_contextual_xes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcxe\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbxe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcxe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbxe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_contextual_xes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_baseline_xes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dialog_mt/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpointbiserialr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4324\u001b[0m     \"\"\"\n\u001b[0;32m-> 4325\u001b[0;31m     \u001b[0mrpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPointbiserialrResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dialog_mt/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   3833\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3835\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x and y must have the same length.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have the same length."
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(f\"Total Acc: {np.stack(corrects).mean().item()}\")\n",
    "print(f\"Total Acc: {np.stack(b_corrects).mean().item()}\")\n",
    "print(scipy.stats.pointbiserialr(np.stack(corrects), [cxe - bxe for cxe, bxe in zip(avg_contextual_xes, avg_baseline_xes)]))\n",
    "print(scipy.stats.pointbiserialr(np.stack([not b_c and c for b_c, c in zip(b_corrects, corrects)]), [cxe - bxe for cxe, bxe in zip(avg_contextual_xes, avg_baseline_xes)]))\n",
    "print(scipy.stats.pearsonr(avg_contextual_xes, [cxe - bxe for cxe, bxe in zip(avg_contextual_xes, avg_baseline_xes)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'm1_xmes' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6d621c3dfc10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1_xmes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2_xmes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"current: {documents[i[0]][i[1]]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"context: {documents[i[0]][i[1]-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm1_xmes' is not defined"
     ]
    }
   ],
   "source": [
    "m1_xmes=[cxe - bxe for cxe, bxe in zip(avg_contextual_xes, avg_baseline_xes)]\n",
    "#m2_xmes=[cxe - bxe for cxe, bxe in zip(avg_contextual_xes, avg_baseline_xes)]\n",
    "\n",
    "\n",
    "for _, i in sorted([(x2 - x1, i) for x1, x2, i in zip(m1_xmes, m2_xmes, ids)], reverse=True):\n",
    "    print(f\"current: {documents[i[0]][i[1]]}\")\n",
    "    print(f\"context: {documents[i[0]][i[1]-1]}\")\n",
    "    input()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}